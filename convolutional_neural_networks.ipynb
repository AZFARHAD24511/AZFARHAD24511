{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "korean-wednesday",
      "metadata": {
        "id": "korean-wednesday"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "You should build an end-to-end machine learning pipeline using a convolutional neural network model. In particular, you should do the following:\n",
        "- Load the `mnist` dataset using [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). You can find this dataset in the datasets folder.\n",
        "- Split the dataset into training and test sets using [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "- Build an end-to-end machine learning pipeline, including a [convolutional neural network](https://keras.io/examples/vision/mnist_convnet/) model.\n",
        "- Optimize your pipeline by validating your design decisions.\n",
        "- Test the best pipeline on the test set and report various [evaluation metrics](https://scikit-learn.org/0.15/modules/model_evaluation.html).  \n",
        "- Check the documentation to identify the most important hyperparameters, attributes, and methods of the model. Use them in practice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Reshape data to fit the model\n",
        "train_images = train_images.reshape((48000, 28, 28, 1))\n",
        "val_images = val_images.reshape((12000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "# Assuming train_images shape is (48000, 28, 28, 1)\n",
        "# Reshape the images to 2D arrays (48000, 28*28)\n",
        "train_images_reshaped = train_images.reshape(train_images.shape[0], -1)\n",
        "\n",
        "# Create a pipeline with StandardScaler and MLPClassifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42))  # Adjust max_iter as needed\n",
        "])\n",
        "\n",
        "# Train the model using the pipeline\n",
        "pipeline.fit(train_images_reshaped, train_labels)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "accuracy = pipeline.score(val_images.reshape(val_images.shape[0], -1), val_labels)\n",
        "print(f\"Validation Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "qsEqqMupMefU"
      },
      "id": "qsEqqMupMefU",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Function to build and train the CNN model\n",
        "def build_and_train_cnn_model(filters1, filters2, dense_units):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(filters1, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(filters2, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(filters2, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(dense_units, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Reshape data to fit the model\n",
        "    train_images_reshaped = train_images.reshape((48000, 28, 28, 1))\n",
        "    val_images_reshaped = val_images.reshape((12000, 28, 28, 1))\n",
        "\n",
        "    model.fit(train_images_reshaped, train_labels, epochs=5, validation_data=(val_images_reshaped, val_labels), verbose=0)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_accuracy = model.evaluate(val_images_reshaped, val_labels)[1]\n",
        "\n",
        "    return val_accuracy\n",
        "\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Parameters to be tested\n",
        "filters1_values = [16, 32]\n",
        "filters2_values = [32, 64]\n",
        "dense_units_values = [32, 64]\n",
        "\n",
        "# Create a table to store results\n",
        "results_table = pd.DataFrame(columns=['Filters1', 'Filters2', 'DenseUnits', 'ValidationAccuracy'])\n",
        "\n",
        "# Iterate over parameter combinations\n",
        "for filters1 in filters1_values:\n",
        "    for filters2 in filters2_values:\n",
        "        for dense_units in dense_units_values:\n",
        "            val_accuracy = build_and_train_cnn_model(filters1, filters2, dense_units)\n",
        "            results_table = results_table.append({'Filters1': filters1,\n",
        "                                                  'Filters2': filters2,\n",
        "                                                  'DenseUnits': dense_units,\n",
        "                                                  'ValidationAccuracy': val_accuracy},\n",
        "                                                  ignore_index=True)\n",
        "\n",
        "# Display the results\n",
        "print(results_table)\n"
      ],
      "metadata": {
        "id": "Z6AkmAnXNJG2",
        "outputId": "7ca1dee2-8b55-4b4d-a312-8dfa9638e0cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Z6AkmAnXNJG2",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0514 - accuracy: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0410 - accuracy: 0.9896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0483 - accuracy: 0.9862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.9875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0444 - accuracy: 0.9870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0509 - accuracy: 0.9858\n",
            "   Filters1  Filters2  DenseUnits  ValidationAccuracy\n",
            "0      16.0      32.0        32.0            0.980167\n",
            "1      16.0      32.0        64.0            0.986417\n",
            "2      16.0      64.0        32.0            0.989583\n",
            "3      16.0      64.0        64.0            0.986250\n",
            "4      32.0      32.0        32.0            0.986333\n",
            "5      32.0      32.0        64.0            0.987500\n",
            "6      32.0      64.0        32.0            0.987000\n",
            "7      32.0      64.0        64.0            0.985750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-7ad8011ff587>:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({'Filters1': filters1,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "XffFiz-QYNqx",
        "outputId": "28751345-3fa8-4ac2-98df-32a01a3b39e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XffFiz-QYNqx",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 13, 13, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 5, 5, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93322 (364.54 KB)\n",
            "Trainable params: 93322 (364.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}